{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from PIL import Image\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de imágenes\n",
    "images_dir = 'arcgis-survey-images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio para guardar el nuevo dataset\n",
    "output_dir = 'processed_dataset'\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "valid_dir = os.path.join(output_dir, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorios de salida si no existen\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(valid_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases encontradas: ['Chinche salivosa', 'Clororis', 'Hoja sana', 'Roya naranja', 'Roya purpura']\n"
     ]
    }
   ],
   "source": [
    "# Obtener las clases a partir de los nombres de los subdirectorios\n",
    "class_names = sorted([d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))])\n",
    "print(f\"Clases encontradas: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas para cada clase en los directorios de entrenamiento y validación\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(valid_dir, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recopilar rutas de imágenes y etiquetas\n",
    "data = []\n",
    "for class_label in class_names:\n",
    "    class_dir = os.path.join(images_dir, class_label)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            data.append({'image': img_path, 'label': class_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imágenes: 3289\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Total de imágenes: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: 2631 imágenes\n",
      "Validación: 658 imágenes\n"
     ]
    }
   ],
   "source": [
    "# Dividir en conjuntos de entrenamiento y validación (80% entrenamiento, 20% validación)\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=123)\n",
    "print(f\"Entrenamiento: {len(train_df)} imágenes\")\n",
    "print(f\"Validación: {len(valid_df)} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de clases desequilibradas en el conjunto de entrenamiento\n",
    "class_counts = train_df['label'].value_counts()\n",
    "max_count = class_counts.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentar las muestras de las clases minoritarias\n",
    "dfs = []\n",
    "for class_label, count in class_counts.items():\n",
    "    df_class = train_df[train_df['label'] == class_label]\n",
    "    if count < max_count:\n",
    "        df_class = resample(df_class,\n",
    "                            replace=True,     # Muestra con reemplazo\n",
    "                            n_samples=max_count,  # Aumentar a max_count\n",
    "                            random_state=123)\n",
    "    dfs.append(df_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_balanced = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar el DataFrame balanceado\n",
    "train_df_balanced = train_df_balanced.sample(frac=1, random_state=123).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para el conjunto de entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Lambda(lambda img: apply_sobel(np.array(img))),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Transformaciones para el conjunto de validación (sin aumentación)\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Lambda(lambda img: apply_sobel(np.array(img))),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset personalizado\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['image']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convertir la etiqueta a un índice\n",
    "        label_idx = class_names.index(label)\n",
    "        return image, label_idx, img_path\n",
    "\n",
    "# Crear datasets y dataloaders\n",
    "train_dataset = CustomDataset(train_df_balanced, transform=train_transforms)\n",
    "valid_dataset = CustomDataset(valid_df, transform=valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para guardar las imágenes procesadas\n",
    "def save_processed_images(loader, save_dir):\n",
    "    for images, labels, paths in loader:\n",
    "        for i in range(len(images)):\n",
    "            # Convertir el tensor a imagen en escala de grises\n",
    "            image_np = images[i].numpy().transpose(1, 2, 0).squeeze() * 255  # Escalar a [0, 255]\n",
    "            \n",
    "            # Verificar si la imagen es en escala de grises y convertir a RGB\n",
    "            if len(image_np.shape) == 2:  # Imagen en escala de grises\n",
    "                image_pil = Image.fromarray(image_np.astype(np.uint8)).convert('RGB')\n",
    "            else:\n",
    "                image_pil = Image.fromarray(image_np.astype(np.uint8))\n",
    "            \n",
    "            # Obtener la etiqueta y el nombre original\n",
    "            label = class_names[labels[i]]\n",
    "            img_name = os.path.basename(paths[i])\n",
    "\n",
    "            # Definir el path de salida\n",
    "            save_path = os.path.join(save_dir, label, img_name)\n",
    "            image_pil.save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar el dataset de entrenamiento procesado\n",
    "save_processed_images(train_loader, train_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes procesadas y guardadas en el directorio: processed_dataset\n"
     ]
    }
   ],
   "source": [
    "# Guardar el dataset de validación procesado\n",
    "save_processed_images(valid_loader, valid_dir)\n",
    "\n",
    "print(\"Imágenes procesadas y guardadas en el directorio:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
